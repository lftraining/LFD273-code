{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67609b90",
   "metadata": {},
   "source": [
    "# Lab Instructions\n",
    "\n",
    "In the lab, you're presented a task such as building a dataset, training a model, or writing a training loop, and we'll provide the code structured in such a way that you can fill in the blanks in the code using the knowledge you acquired in the chapters that precede the lab. You should be able to find appropriate snippets of code in the course content that work well in the lab with minor or no adjustments.\n",
    "\n",
    "The blanks in the code are indicated by ellipsis (`...`) and comments (`# write your code here`).\n",
    "\n",
    "In some cases, we'll provide you partial code to ensure the right variables are populated and any code that follows it runs accordingly.\n",
    "\n",
    "```python\n",
    "# write your code here\n",
    "x = ...\n",
    "```\n",
    "\n",
    "The solution should be a single statement that replaces the ellipsis, such as:\n",
    "\n",
    "```python\n",
    "# write your code here\n",
    "x = [0, 1, 2]\n",
    "```\n",
    "\n",
    "In some other cases, when there is no new variable being created, the blanks are shown like in the example below: \n",
    "\n",
    "```python\n",
    "# write your code here\n",
    "...\n",
    "```\n",
    "\n",
    "Although we're showing you only a single ellipsis (`...`), you may have to write more than one line of code to complete the step, such as:\n",
    "\n",
    "```python\n",
    "# write your code here\n",
    "for i, xi in enumerate(x):\n",
    "    x[i] = xi * 2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b674d35",
   "metadata": {},
   "source": [
    "## 3.12 Lab 1B: Non-Linear Regression\n",
    "\n",
    "In this lab, we will keep using the same [Auto MPG Dataset](https://archive.ics.uci.edu/ml/datasets/auto+mpg), and we'll be building upon the previous lab (Lab 1A).\n",
    "\n",
    "The columns, or attributes, of this dataset, are as follows:\n",
    "\n",
    "1. mpg: continuous\n",
    "2. cylinders: multi-valued discrete\n",
    "3. displacement: continuous\n",
    "4. horsepower: continuous\n",
    "5. weight: continuous\n",
    "6. acceleration: continuous\n",
    "7. model year: multi-valued discrete\n",
    "8. origin: multi-valued discrete\n",
    "9. car name: string (unique for each instance)\n",
    "\n",
    "Remember that the last column, `car name`, is actually separated by tabs (instead of spaces), so we're considering the cars' names as comments while loading the dataset.\n",
    "\n",
    "The following section offers a quick recap of the work done in the previous lab. You're welcome to use your own solution as starting point, but please keep in mind that you may need to do some adjustments in this case. We suggest you work on this lab using the suggested recap first and, only once you're finished try replacing the recap with your own code.\n",
    "\n",
    "### 3.12.1 Recap\n",
    "\n",
    "Let's recap what we did in the last lab to properly load and preprocess our dataset, so we can use it to train a non-linear regression in PyTorch. You may run all the cells in this section as they are.\n",
    "\n",
    "![](https://raw.githubusercontent.com/dvgodoy/assets/main/PyTorchInPractice/images/ch0/data_step1.png)\n",
    "\n",
    "First, we loaded the data into a Pandas dataframe and split it into training, validation, and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e72c076",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "19806f07",
    "outputId": "fde4c269-0342-416f-9b6b-b067e8428958"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data'\n",
    "column_names = ['mpg', 'cyl', 'disp', 'hp', 'weight', 'acc', 'year', 'origin']\n",
    "\n",
    "df = pd.read_csv(url, names=column_names, na_values='?', comment='\\t', sep=' ', skipinitialspace=True)\n",
    "\n",
    "shuffled = df.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "raw_data = {}\n",
    "trainval, raw_data['test'] = train_test_split(shuffled, test_size=0.16, shuffle=False)\n",
    "raw_data['train'], raw_data['val'] = train_test_split(trainval, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd29a03",
   "metadata": {},
   "source": [
    "Next, we dropped any rows with missing values in them:\n",
    "\n",
    "![](https://raw.githubusercontent.com/dvgodoy/assets/main/PyTorchInPractice/images/ch0/data_step2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "591accd4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "4108b0d8",
    "outputId": "c1600eaa-e80b-4ca0-bcf0-78b4a38803af"
   },
   "outputs": [],
   "source": [
    "for k in raw_data.keys():\n",
    "    raw_data[k].dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309809bb",
   "metadata": {},
   "source": [
    "In Chapter 1, we wrote helper functions to both standardize continuous attributes and encode categorical attributes as sequential indices, so they can be used to retrieve embeddings later:\n",
    "\n",
    "![](https://raw.githubusercontent.com/dvgodoy/assets/main/PyTorchInPractice/images/ch0/data_step3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c84f95d4",
   "metadata": {
    "id": "49139e2b"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "def standardize(df, cont_attr, scaler=None):\n",
    "    cont_X = df[cont_attr].values\n",
    "    if scaler is None:\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(cont_X)\n",
    "    cont_X = scaler.transform(cont_X)\n",
    "    cont_X = torch.as_tensor(cont_X, dtype=torch.float32)\n",
    "    return cont_X, scaler\n",
    "\n",
    "def encode(df, cat_attr, encoder=None):\n",
    "    cat_X = df[cat_attr].values\n",
    "    if encoder is None:\n",
    "        encoder = OrdinalEncoder()\n",
    "        encoder.fit(cat_X)\n",
    "    cat_X = encoder.transform(cat_X)\n",
    "    cat_X = torch.as_tensor(cat_X, dtype=torch.int)\n",
    "    return cat_X, encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451522ac",
   "metadata": {},
   "source": [
    "In the previous lab, we built a custom dataset that returned a tuple `(features, target)` where the `features` element was a tuple `(cont_X, cat_X)` itself:\n",
    "\n",
    "![](https://raw.githubusercontent.com/dvgodoy/assets/main/PyTorchInPractice/images/ch0/data_step4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54d7211a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://github.com/yashu-seth/pytorch-tabular\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, raw_data, cont_attr, disc_attr, target_col, scaler=None, encoder=None):\n",
    "        self.n = raw_data.shape[0]\n",
    "        self.target = torch.as_tensor(raw_data[[target_col]].values, dtype=torch.float32)\n",
    "        self.cont_data, self.scaler = standardize(raw_data, cont_attr, scaler)\n",
    "        self.cat_data, self.encoder = encode(raw_data, disc_attr, encoder)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        features = (self.cont_data[idx], self.cat_data[idx])\n",
    "        target = self.target[idx]\n",
    "        return (features, target)\n",
    "    \n",
    "    \n",
    "cont_attr = ['disp', 'hp', 'weight', 'acc']\n",
    "disc_attr = ['cyl', 'origin']\n",
    "target_col = 'mpg'\n",
    "\n",
    "datasets = {'train': None, 'val': None, 'test': None}\n",
    "datasets['train'] = TabularDataset(raw_data['train'], cont_attr, disc_attr, target_col)\n",
    "datasets['val'] = TabularDataset(raw_data['val'], cont_attr, disc_attr, target_col, \n",
    "                                 datasets['train'].scaler, datasets['train'].encoder)\n",
    "datasets['test'] = TabularDataset(raw_data['test'], cont_attr, disc_attr, target_col, \n",
    "                                  datasets['train'].scaler, datasets['train'].encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c60c2d",
   "metadata": {},
   "source": [
    "Once the datasets are ready, we created data loaders so we can load mini-batches of data, one at a time:\n",
    "\n",
    "![](https://raw.githubusercontent.com/dvgodoy/assets/main/PyTorchInPractice/images/ch0/data_step5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "086f612c",
   "metadata": {
    "id": "fc647a8f"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloaders = {'train': None, 'val': None, 'test': None}\n",
    "dataloaders['train'] = DataLoader(datasets['train'], batch_size=32, shuffle=True, drop_last=True)\n",
    "dataloaders['val'] = DataLoader(datasets['val'], batch_size=16, drop_last=True)\n",
    "dataloaders['test'] = DataLoader(datasets['test'], batch_size=16, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a015ca46",
   "metadata": {},
   "source": [
    "Finally, we may fetch one mini-batch of data, and we'll use it to try out the model we're about to build:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48866e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "(cont_feat, cat_feat), targets = next(iter(dataloaders['train']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736267b9",
   "metadata": {
    "id": "1259b83e"
   },
   "source": [
    "### 3.12.2 Embeddings: From Categorical to Continuous\n",
    "\n",
    "Write code to create a list of embedding layers, each layer configured to handle one particular attribute, that is, one layer to embed `cyl` and another one to embed `origin`. You're free to choose the number of elements/dimensions that the resulting arrays will have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6bd724d",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = datasets['train'].encoder\n",
    "\n",
    "embedding_layers = []\n",
    "\n",
    "# write your code here\n",
    "emb_dim = ...\n",
    "\n",
    "for categories in encoder.categories_:\n",
    "    # write your code here\n",
    "    layer = ...\n",
    "    embedding_layers.append(layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8806b39",
   "metadata": {},
   "source": [
    "Just run the cell below as is to visualize the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43188093",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "51331cbb",
    "outputId": "cc05481f-e5b1-4b8e-f0e0-1b136dc41954"
   },
   "outputs": [],
   "source": [
    "embedding_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa645a5b",
   "metadata": {
    "id": "92234516"
   },
   "source": [
    "Now, try out your layers by embedding the first five rows of your categorical training data. You should get a list containing two tensors with five rows and as many columns/dimensions as you choose in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65ca7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "\n",
    "for i in range(encoder.n_features_in_):\n",
    "    data = cat_feat[:5, i]\n",
    "    \n",
    "    # write your code here\n",
    "    emb_values = ...\n",
    "    \n",
    "    embeddings.append(emb_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244ec6e2",
   "metadata": {},
   "source": [
    "Just run the cell below as is to visualize the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58197c94",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "317ac453",
    "outputId": "35bcfdf3-120c-40a4-d90a-aa940777ba80"
   },
   "outputs": [],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab9fec7",
   "metadata": {
    "id": "65271f6f"
   },
   "source": [
    "In practice, thoug, your model won't be using a list of embeddings, but their concatenation along the horizontal axis instead. You can use `torch.cat` to accomplish this. Just run the cell below as is to visualize the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a355f32c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0474adff",
    "outputId": "381ca666-0124-4822-8d25-e8e42963ef7c"
   },
   "outputs": [],
   "source": [
    "torch.cat(embeddings, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56350d59",
   "metadata": {
    "id": "3d6881ae"
   },
   "source": [
    "Now your categorical attributes are represented by many (learned) numerical features. Later on, when building your model, you will have to concatenate both the original continuous features, and those learned via embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7b3938",
   "metadata": {
    "id": "cfbf0b18"
   },
   "source": [
    "### 3.12.3 Custom Model\n",
    "\n",
    "![](https://raw.githubusercontent.com/dvgodoy/assets/main/PyTorchInPractice/images/ch0/model_step1.png)\n",
    "\n",
    "Your next task is to build a custom model that can handle continuous and categorical features (via embeddings), and that is non-linear in nature. Before moving on, let's briefly discuss two topics: `ModuleList` and the importance of non-linearities.\n",
    "\n",
    "#### 3.12.3.1 `ModuleList`\n",
    "\n",
    "`ModuleList` is a special type of list, one that allows PyTorch to recursively look for learnable parameters of layers and model inside its contents. As it turns out, if the class attribute of your custom model is a regular Python list, any layers or models inside it will be ignore by PyTorch during training. By explicitly making a `ModuleList` out of a regular Python list we ensure that its parameters are also accounted for.\n",
    "\n",
    "In our custom model, we have a list of embedding layers, one for each categorical attribute. Therefore, if we want our model to properly learn these embeeddings, we need to make it a `ModuleList`.\n",
    "\n",
    "#### 3.12.3.2 Methods\n",
    "\n",
    "A custom model class must implement a couple of methods:\n",
    "- `__init__(self)`\n",
    "- `forward(self, x)`\n",
    "\n",
    "In the constructor method, you will define the parts that make up your model, like linear layers and embeddings, as class attributes. Don't forget to include a call to `super().__init__()` at the top of the method so it executes the code from the parent class before your own. In our case, the model will receive the following arguments:\n",
    "\n",
    "- `n_cont`: the number of continuous attributes\n",
    "- `cat_list`: a list of lists of unique values of categorical attributes (as returned by the `categories_` property of the `OrdinalEncoder`)\n",
    "- `emb_dim`: the number of dimensions of each embedding (we're keeping them the same for every categorical attribute for simplicity)\n",
    "\n",
    "The `forward()` method is where the magic happens, as you know. It receives an input `x`, which can be anything (e.g. a tensor, a tuple, a dictionary), and forwards this input through your model's components, such as layers, activation functions, and embeddings. In the end, it should return a prediction. The diagram below illustrates the flow of the inputs through the model's components in the forward pass. Please refer to it for its implementation.\n",
    "\n",
    "![](https://raw.githubusercontent.com/dvgodoy/assets/main/PyTorchInPractice/images/ch3/lab1_model.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb986e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class FFN(nn.Module):\n",
    "    def __init__(self, n_cont, cat_list, emb_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Embedding layers\n",
    "        embedding_layers = []\n",
    "        # Creates one embedding layer for each categorical feature\n",
    "        # just like you did in the previous section\n",
    "        # write your code here\n",
    "        ...\n",
    "        \n",
    "        self.emb_layers = nn.ModuleList(embedding_layers)\n",
    "\n",
    "        # Total number of embedding dimensions\n",
    "        self.n_emb = len(cat_list) * emb_dim\n",
    "        self.n_cont = n_cont\n",
    "\n",
    "        # Linear Layer(s)\n",
    "        lin_layers = []\n",
    "        \n",
    "        # The input layers takes as many inputs as the number of continuous features\n",
    "        # plus the total number of concatenated embeddings\n",
    "        \n",
    "        # The number of outputs is your own choice\n",
    "        # Optionally, add more hidden layers, don't forget to match the dimensions if you do\n",
    "\n",
    "        # write your code here\n",
    "        ...\n",
    "        \n",
    "        self.lin_layers = nn.ModuleList(lin_layers)\n",
    "        \n",
    "        # The output layer must have as many inputs as there were outputs in the last hidden layer\n",
    "        # write your code here\n",
    "        self.output_layer = ...\n",
    "\n",
    "        # Layer initialization - initialization scheme\n",
    "        for lin_layer in self.lin_layers:\n",
    "            nn.init.kaiming_normal_(lin_layer.weight.data, nonlinearity='relu')\n",
    "        nn.init.kaiming_normal_(self.output_layer.weight.data, nonlinearity='relu')\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # The inputs are the features as returned in the first element of a tuple\n",
    "        # coming from the dataset/dataloader\n",
    "        # Make sure you split it into continuous and categorical attributes according\n",
    "        # to your dataset implementation of __getitem__\n",
    "        cont_data, cat_data = inputs\n",
    "        \n",
    "        # Retrieve embeddings for each categorical attribute and concatenate them\n",
    "        embeddings = []\n",
    "        \n",
    "        # write your code here\n",
    "        ...\n",
    "        \n",
    "        embeddings = torch.cat(embeddings, 1)\n",
    "        \n",
    "        # Concatenate all features together, continuous and embeddings\n",
    "        # write your code here\n",
    "        x = ...\n",
    "        \n",
    "        # Run the inputs through each layer and applies an activation function to each output\n",
    "        for layer in self.lin_layers:\n",
    "            # write your code here\n",
    "            ...\n",
    "            \n",
    "        # Run the output of the last linear layer through the output layer\n",
    "        # write your code here\n",
    "        ...\n",
    "        \n",
    "        # Return the prediction\n",
    "        # write your code here\n",
    "        return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546437bc",
   "metadata": {
    "id": "ce91b059"
   },
   "source": [
    "### 3.12.4 Training\n",
    "\n",
    "Now it is time to write your own training loop. First, you need to instantiate your model.\n",
    "\n",
    "![](https://raw.githubusercontent.com/dvgodoy/assets/main/PyTorchInPractice/images/ch0/model_step1.png)\n",
    "\n",
    "Just run the cell below as is to populate a few variables and visualize the outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cca667",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1f99cb57",
    "outputId": "02cea2f4-f4f1-4594-9ec4-8e12c06e6680"
   },
   "outputs": [],
   "source": [
    "scaler = datasets['train'].scaler\n",
    "encoder = datasets['train'].encoder\n",
    "\n",
    "n_cont = scaler.n_features_in_\n",
    "cat_list = encoder.categories_\n",
    "\n",
    "n_cont, cat_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e0170c",
   "metadata": {},
   "source": [
    "The `n_cont` variable contains the number of continuous attributes you're using, and that were scaled by the `StandardScaler`. The `cat_list` variable contains a list of lists, each inner list containing the unique values corresponding to one of the categorical attributes.\n",
    "\n",
    "Both variables, together with the number of embedding dimensions you chose earlier (`emb_dim`), should be used as arguments to create an instance of your custom model class (`FFN`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1c5078",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# write your code here\n",
    "model = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5085f66d",
   "metadata": {},
   "source": [
    "Now, create the appropriate loss function for the task:\n",
    "\n",
    "![](https://raw.githubusercontent.com/dvgodoy/assets/main/PyTorchInPractice/images/ch0/model_step2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5fd7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n",
    "loss_fn = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52f854a",
   "metadata": {},
   "source": [
    "Then, create an optimizer that will update your model's parameters:\n",
    "\n",
    "![](https://raw.githubusercontent.com/dvgodoy/assets/main/PyTorchInPractice/images/ch0/model_step3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bb89c9",
   "metadata": {
    "id": "8eb530a2"
   },
   "outputs": [],
   "source": [
    "# Suggested learning rate\n",
    "lr = 1e-2\n",
    "\n",
    "# write your code here\n",
    "optimizer = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dd7803",
   "metadata": {},
   "source": [
    "Next, you will write the training loop using the data loaders to iterate through your training and validation data (these loops are written for you already).\n",
    "\n",
    "![](https://raw.githubusercontent.com/dvgodoy/assets/main/PyTorchInPractice/images/ch0/model_step4.png)\n",
    "\n",
    "The features returned by our dataset are tuples (as opposed to simple tensors), so don't forget to send each one of its components to the appropriate device. \n",
    "\n",
    "Remember that model's have two modes, training and evaluation, set them accordingly. Optionally, you can also implement early stopping.\n",
    "\n",
    "Use the model, optimizer, and loss function you just created to perform the four steps inside the training loop: forward pass, computing losses, computing gradients, and updating parameters. Don't forget to zero the gradients too.\n",
    "\n",
    "***\n",
    "**ASIDE: TQDM**\n",
    "\n",
    "[TQDM](https://github.com/tqdm/tqdm) is a nice and simple Python package that works as a progress bar for loops. You simply wrap whatever you're looping over with a call to `tqdm()` and you get a working progress bar.\n",
    "\n",
    "In the code below, we set the progress bar like this:\n",
    "\n",
    "```python\n",
    "progress_bar = tqdm(range(n_epochs))\n",
    "\n",
    "for epoch in progress_bar:\n",
    "    # do your magic here\n",
    "```\n",
    "\n",
    "As the loop runs, it will print a progress bar below the running cell.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b890821",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b65e2cec",
    "outputId": "b6a77ffd-2835-41c3-950b-8d2b4494ed75"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "n_epochs = 100\n",
    "\n",
    "losses = torch.empty(n_epochs)\n",
    "val_losses = torch.empty(n_epochs)\n",
    "\n",
    "best_loss = torch.inf\n",
    "best_epoch = -1\n",
    "patience = 3\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "progress_bar = tqdm(range(n_epochs))\n",
    "\n",
    "for epoch in progress_bar:\n",
    "    batch_losses = torch.empty(len(dataloaders['train']))\n",
    "    \n",
    "    ## Training\n",
    "    for i, (batch_features, batch_targets) in enumerate(dataloaders['train']):\n",
    "        # Set the model to training mode\n",
    "        # write your code here\n",
    "        ...\n",
    "        \n",
    "        # Send batch features and targets to the device\n",
    "        # write your code here\n",
    "        ...\n",
    "        \n",
    "        # Step 1 - forward pass\n",
    "        predictions = ...\n",
    "\n",
    "        # Step 2 - computing the loss\n",
    "        loss = ...\n",
    "\n",
    "        # Step 3 - computing the gradients\n",
    "        # Tip: it requires a single method call to backpropagate gradients\n",
    "        # write your code here\n",
    "        ...\n",
    "        \n",
    "        batch_losses[i] = loss.item()\n",
    "\n",
    "        # Step 4 - updating parameters and zeroing gradients\n",
    "        # Tip: it takes two calls to optimizer's methods\n",
    "        # write your code here\n",
    "        ...\n",
    "        \n",
    "    losses[epoch] = batch_losses.mean()\n",
    "\n",
    "    ## Validation   \n",
    "    with torch.inference_mode():\n",
    "        batch_losses = torch.empty(len(dataloaders['val']))    \n",
    "\n",
    "        for i, (val_features, val_targets) in enumerate(dataloaders['val']):\n",
    "            # Set the model to evaluation mode\n",
    "            # write your code here\n",
    "            ...\n",
    "\n",
    "            # Send batch features and targets to the device\n",
    "            # write your code here\n",
    "            ...\n",
    "\n",
    "            # Step 1 - forward pass\n",
    "            predictions = ...\n",
    "\n",
    "            # Step 2 - computing the loss\n",
    "            loss = ...\n",
    "            \n",
    "            batch_losses[i] = loss.item()\n",
    "\n",
    "        val_losses[epoch] = batch_losses.mean()\n",
    "        \n",
    "        if val_losses[epoch] < best_loss:\n",
    "            best_loss = val_losses[epoch]\n",
    "            best_epoch = epoch\n",
    "            torch.save({'model': model.state_dict(), \n",
    "                        'optimizer': optimizer.state_dict()}, 'best_model.pth')\n",
    "        elif (epoch - best_epoch) > patience:\n",
    "            print(f\"Early stopping at epoch #{epoch}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ba69b9",
   "metadata": {
    "id": "e63e8eb6"
   },
   "source": [
    "Let's check the evolution of the losses. Run the cell below as is to plot your losses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4c016f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "15f28dc0",
    "outputId": "7586ba0d-8794-4823-da8d-49b53fee1a6f"
   },
   "outputs": [],
   "source": [
    "plt.plot(losses[:epoch], label='Training')\n",
    "plt.plot(val_losses[:epoch], label='Validation')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.yscale('log')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6f0327",
   "metadata": {
    "id": "4c00b48e"
   },
   "source": [
    "Then, let's compare predicted and actual values in the validation set. Hopefully, it will be much better than our former linear regression. \n",
    "\n",
    "![](https://raw.githubusercontent.com/dvgodoy/assets/main/PyTorchInPractice/images/ch0/model_step5.png)\n",
    "\n",
    "Run the cell below as is to visualize a scatterplot comparing predicted and actual values of fuel consumption. A perfect prediction corresponds to the dashed diagonal line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95ea7d2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 505
    },
    "id": "e7a8c2e1",
    "outputId": "270a686a-3493-4ad2-ea01-c5335fdf16bb"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "split = 'val'\n",
    "batch = list(datasets[split][:][0])\n",
    "batch[0] = batch[0].to(device)\n",
    "batch[1] = batch[1].to(device)\n",
    "ax.scatter(datasets[split][:][1].tolist(), model(batch).tolist(), alpha=.5)\n",
    "ax.plot([0, 45], [0, 45], linestyle='--', c='k', linewidth=1)\n",
    "ax.set_xlabel('Actual')\n",
    "ax.set_xlim([0, 45])\n",
    "ax.set_ylabel('Predicted')\n",
    "ax.set_ylim([0, 45])\n",
    "ax.set_title('MPG')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
