{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67609b90",
   "metadata": {},
   "source": [
    "# Lab Instructions\n",
    "\n",
    "In the lab, you're presented a task such as building a dataset, training a model, or writing a training loop, and we'll provide the code structured in such a way that you can fill in the blanks in the code using the knowledge you acquired in the chapters that precede the lab. You should be able to find appropriate snippets of code in the course content that work well in the lab with minor or no adjustments.\n",
    "\n",
    "The blanks in the code are indicated by ellipsis (`...`) and comments (`# write your code here`).\n",
    "\n",
    "In some cases, we'll provide you partial code to ensure the right variables are populated and any code that follows it runs accordingly.\n",
    "\n",
    "```python\n",
    "# write your code here\n",
    "x = ...\n",
    "```\n",
    "\n",
    "The solution should be a single statement that replaces the ellipsis, such as:\n",
    "\n",
    "```python\n",
    "# write your code here\n",
    "x = [0, 1, 2]\n",
    "```\n",
    "\n",
    "In some other cases, when there is no new variable being created, the blanks are shown like in the example below: \n",
    "\n",
    "```python\n",
    "# write your code here\n",
    "...\n",
    "```\n",
    "\n",
    "Although we're showing you only a single ellipsis (`...`), you may have to write more than one line of code to complete the step, such as:\n",
    "\n",
    "```python\n",
    "# write your code here\n",
    "for i, xi in enumerate(x):\n",
    "    x[i] = xi * 2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8d017e",
   "metadata": {
    "id": "bd8d017e"
   },
   "source": [
    "## 5.4 Lab 2: Price Prediction\n",
    "\n",
    "In this lab, we'll keep using the [100,000 UK Used Car Dataset](https://www.kaggle.com/datasets/adityadesai13/used-car-dataset-ford-and-mercedes) from Kaggle. It contains scraped data of used car listings split into CSV files according to the manufacturer: Audi, BMW, Ford, Hyundai, Mercedes, Skoda, Toyota, Vauxhall, and VW. It also contains a few extra files of particular models (`cclass.csv`, `focus.csv`, `unclean_cclass.csv`, and `unclean_focus.csv`) that we won't be using.\n",
    "\n",
    "Each file has nine columns with the car's attributes: model, year, price, transmission, mileage, fuel type, road tax, fuel consumption (mpg), and engine size. Transmission, fuel type, and year are discrete/categorical attributes, the others are continous. Our goal here is to predict the car's price based on its other attributes.\n",
    "\n",
    "We'll start by building a datapipe that reads all the information from the CSV files, and then we'll use this datapipe as a drop-in replacement for the dataset we typically use with data loaders. The use of datapipes in its functional form, will illustrate some of the challenges when dealing with real-world data.\n",
    "\n",
    "To download the dataset, you'll need to create a Kaggle account. In the following sections, we're assuming the dataset was downloaded and unzipped to a local folder named `car_prices`. Alternatively, you can download it from the following link:\n",
    "\n",
    "```\n",
    "https://github.com/dvgodoy/assets/raw/main/PyTorchInPractice/data/100KUsedCar/car_prices.zip\n",
    "```\n",
    "\n",
    "In Colab, you can run the following commands to download and unzip the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca4ebe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/dvgodoy/assets/raw/main/PyTorchInPractice/data/100KUsedCar/car_prices.zip\n",
    "!unzip car_prices.zip -d car_prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5527f1",
   "metadata": {},
   "source": [
    "### 5.4.1 Recap\n",
    "\n",
    "Let's recap what we did in Chapter 3 to load our data into a datapipe, so we can use it to train a new model in PyTorch. You may run all the cells in this section as they are."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6180c09",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/dvgodoy/assets/main/PyTorchInPractice/images/ch0/data_step3.png)\n",
    "\n",
    "First, we built the \"dropdown\" dictionaries that we used to preprocess the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f399cb",
   "metadata": {
    "id": "38f399cb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchdata.datapipes as dp\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def filter_for_data(filename):\n",
    "    return (\"unclean\" not in filename) and (\"focus\" not in filename) and (\"cclass\" not in filename) and filename.endswith(\".csv\")\n",
    "\n",
    "def get_manufacturer(content):\n",
    "    path, data = content\n",
    "    manuf = os.path.splitext(os.path.basename(path))[0].upper()\n",
    "    data.extend([manuf])\n",
    "    return data\n",
    "\n",
    "def gen_encoder_dict(series):\n",
    "    values = series.unique()\n",
    "    return dict(zip(values, range(len(values))))\n",
    "\n",
    "tmp_dp = dp.iter.FileLister('./car_prices')\n",
    "tmp_dp = tmp_dp.filter(filter_fn=filter_for_data)\n",
    "tmp_dp = tmp_dp.open_files(mode='rt')\n",
    "tmp_dp = tmp_dp.parse_csv(delimiter=\",\", skip_lines=1, return_path=True)\n",
    "tmp_dp = tmp_dp.map(get_manufacturer)\n",
    "\n",
    "colnames = ['model', 'year', 'price', 'transmission', 'mileage', 'fuel_type', 'road_tax', 'mpg', 'engine_size', 'manufacturer']\n",
    "df = pd.DataFrame(list(tmp_dp), columns=colnames)\n",
    "\n",
    "N_ROWS = len(df)\n",
    "\n",
    "cont_attr = ['year', 'mileage', 'road_tax', 'mpg', 'engine_size']\n",
    "cat_attr = ['model', 'transmission', 'fuel_type', 'manufacturer']\n",
    "\n",
    "dropdown_encoders = {col: gen_encoder_dict(df[col]) for col in cat_attr}\n",
    "\n",
    "def preproc(row):\n",
    "    colnames = ['model', 'year', 'price', 'transmission', 'mileage', 'fuel_type', 'road_tax', 'mpg', 'engine_size', 'manufacturer']\n",
    "    \n",
    "    cat_attr = ['model', 'transmission', 'fuel_type', 'manufacturer']\n",
    "    cont_attr = ['year', 'mileage', 'road_tax', 'mpg', 'engine_size']\n",
    "    target = 'price'\n",
    "    \n",
    "    vals = dict(zip(colnames, row))\n",
    "    cont_X = [float(vals[name]) for name in cont_attr]\n",
    "    cat_X = [dropdown_encoders[name][vals[name]] for name in cat_attr]\n",
    "            \n",
    "    return {'label': np.array([float(vals[target])], dtype=np.float32),\n",
    "            'cont_X': np.array(cont_X, dtype=np.float32), \n",
    "            'cat_X': np.array(cat_X, dtype=int)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6464026",
   "metadata": {
    "id": "a7175bc3"
   },
   "source": [
    "Next, we used the preprocessing function to build our main datapipe:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a2ce71",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/dvgodoy/assets/main/PyTorchInPractice/images/ch0/data_step4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32525cf7",
   "metadata": {
    "id": "32525cf7"
   },
   "outputs": [],
   "source": [
    "datapipe = dp.iter.FileLister('./car_prices')\n",
    "datapipe = datapipe.filter(filter_fn=filter_for_data)\n",
    "datapipe = datapipe.open_files(mode='rt')\n",
    "datapipe = datapipe.parse_csv(delimiter=\",\", skip_lines=1, return_path=True)\n",
    "datapipe = datapipe.map(get_manufacturer)\n",
    "datapipe = datapipe.map(preproc)\n",
    "\n",
    "datapipes = {}\n",
    "datapipes['train'] = datapipe.random_split(total_length=N_ROWS, weights={\"train\": 0.8, \"val\": 0.1, \"test\": 0.1}, seed=11, target='train')\n",
    "datapipes['val'] = datapipe.random_split(total_length=N_ROWS, weights={\"train\": 0.8, \"val\": 0.1, \"test\": 0.1}, seed=11, target='val')\n",
    "datapipes['test'] = datapipe.random_split(total_length=N_ROWS, weights={\"train\": 0.8, \"val\": 0.1, \"test\": 0.1}, seed=11, target='test')\n",
    "\n",
    "datapipes['train'] = datapipes['train'].shuffle(buffer_size=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4f5197",
   "metadata": {
    "id": "4afed88a"
   },
   "source": [
    "Once the datapipes are ready, we created data loaders so we can load mini-batches of data, one at a time:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc56af7",
   "metadata": {
    "id": "40ee0a98"
   },
   "source": [
    "![](https://raw.githubusercontent.com/dvgodoy/assets/main/PyTorchInPractice/images/ch0/data_step5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2e8993",
   "metadata": {
    "id": "ac2e8993"
   },
   "outputs": [],
   "source": [
    "dataloaders = {}\n",
    "dataloaders['train'] = DataLoader(dataset=datapipes['train'], batch_size=128, drop_last=True, shuffle=True)\n",
    "dataloaders['val'] = DataLoader(dataset=datapipes['val'], batch_size=128)\n",
    "dataloaders['test'] = DataLoader(dataset=datapipes['test'], batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14b9812",
   "metadata": {
    "id": "d14b9812"
   },
   "source": [
    "### 5.4.3 Custom Model\n",
    "\n",
    "![](https://raw.githubusercontent.com/dvgodoy/assets/main/PyTorchInPractice/images/ch0/model_step1.png)\n",
    "\n",
    "You know the drill: write a custom model class that implements both `__init__()` and `forward()` methods. You can use the model you wrote in Lab 1 as a starting point.\n",
    "\n",
    "In the constructor method, you will define the parts that make up your model, like linear layers and embeddings, as class attributes. Don't forget to include a call to `super().__init__()` at the top of the method so it executes the code from the parent class before your own. In our case, the model will receive the following arguments:\n",
    "\n",
    "- `n_cont`: the number of continuous attributes\n",
    "- `cat_list`: a list of lists of unique values of categorical attributes (as returned by the `categories_` property of the `OrdinalEncoder`)\n",
    "- `emb_dim`: the number of dimensions of each embedding (we're keeping them the same for every categorical attribute for simplicity)\n",
    "\n",
    "The `forward()` method is where the magic happens, as you know. It receives an input `x`, which can be anything (e.g. a tensor, a tuple, a dictionary), and forwards this input through your model's components, such as layers, activation functions, and embeddings. In the end, it should return a prediction.\n",
    "\n",
    "Don't forget your data loader is returning dictionaries now, you'll need to make adjustments to how your model treats its inputs. Also, don't forget to add a batch normalization layer to preprocess the continuous attributes and, optionally, you can also add batch normalization layers after each hidden linear layer. Please refer to the diagram below for the implementation.\n",
    "\n",
    "![](https://raw.githubusercontent.com/dvgodoy/assets/main/PyTorchInPractice/images/ch3/lab2_model.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19e2712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FFN(nn.Module):\n",
    "    def __init__(self, n_cont, cat_list, emb_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Embedding layers\n",
    "        embedding_layers = []\n",
    "        # Creates one embedding layer for each categorical feature\n",
    "\n",
    "        # write your code here\n",
    "        for categories in cat_list:\n",
    "            embedding_layers.append(nn.Embedding(len(categories), emb_dim))        \n",
    "\n",
    "        self.emb_layers = nn.ModuleList(embedding_layers)\n",
    "\n",
    "        # Total number of embedding dimensions\n",
    "        self.n_emb = len(cat_list) * emb_dim\n",
    "        self.n_cont = n_cont\n",
    "        # Batch Normalization layer for continuous features\n",
    "        self.bn_input = nn.BatchNorm1d(n_cont)\n",
    "\n",
    "        # Linear Layer(s)\n",
    "        lin_layers = []\n",
    "        # The input layers takes as many inputs as the number of continuous features\n",
    "        # plus the total number of concatenated embeddings\n",
    "        # The number of outputs is your own choice\n",
    "        # Optionally, add more hidden layers, don't forget to match the dimensions if you do\n",
    "        # write your code here\n",
    "        lin_layers.append(nn.Linear(self.n_emb + self.n_cont, 100))\n",
    "        self.lin_layers = nn.ModuleList(lin_layers)\n",
    "\n",
    "        # Batch Normalization Layer(s)\n",
    "        bn_layers = []\n",
    "        # Creates batch normalization layers for each linear hidden layer\n",
    "\n",
    "        # write your code here\n",
    "        bn_layers.append(nn.BatchNorm1d(100))\n",
    "        self.bn_layers = nn.ModuleList(bn_layers)\n",
    "        \n",
    "        # The output layer must have as many inputs as there were outputs in the last hidden layer\n",
    "        # write your code here\n",
    "        self.output_layer = nn.Linear(self.lin_layers[-1].out_features, 1)\n",
    "\n",
    "        # Layer initialization\n",
    "        for lin_layer in self.lin_layers:\n",
    "            nn.init.kaiming_normal_(lin_layer.weight.data, nonlinearity='relu')\n",
    "        nn.init.kaiming_normal_(self.output_layer.weight.data, nonlinearity='relu')\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # The inputs are the features as returned in the first element of a tuple\n",
    "        # coming from the dataset/dataloader\n",
    "        # Make sure you split it into continuous and categorical attributes according\n",
    "        # to your dataset implementation of __getitem__\n",
    "        # write your code here\n",
    "        cont_data, cat_data = inputs['cont_X'], inputs['cat_X']\n",
    "        \n",
    "        # Retrieve embeddings for each categorical attribute and concatenate them\n",
    "        embeddings = []\n",
    "        # write your code here\n",
    "        for i, layer in enumerate(self.emb_layers):\n",
    "            embeddings.append(layer(cat_data[:, i]))\n",
    "        embeddings = torch.cat(embeddings, 1)\n",
    "        \n",
    "        # Normalizes continuous features using Batch Normalization layer\n",
    "        normalized_cont_data = self.bn_input(cont_data)\n",
    "        \n",
    "        # Concatenate all features together, normalized continuous and embeddings\n",
    "        # write your code here\n",
    "        x = torch.cat([normalized_cont_data, embeddings], 1)\n",
    "        \n",
    "        # Run the inputs through each layer and applies an activation function and batch norm to each output\n",
    "        for layer, bn_layer in zip(self.lin_layers, self.bn_layers):\n",
    "            # write your code here\n",
    "            x = layer(x)\n",
    "            x = F.relu(x)\n",
    "            x = bn_layer(x)\n",
    "            \n",
    "        # Run the output of the last linear layer through the output layer\n",
    "        # write your code here\n",
    "        x = self.output_layer(x)\n",
    "        \n",
    "        # Return the prediction\n",
    "        # write your code here\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11d1d4f",
   "metadata": {},
   "source": [
    "### 5.4.4 Training\n",
    "\n",
    "Now it is time to write your own training loop once again. First, you need to instantiate your model.\n",
    "\n",
    "![](https://raw.githubusercontent.com/dvgodoy/assets/main/PyTorchInPractice/images/ch0/model_step1.png)\n",
    "\n",
    "Just run the cell below as is to populate a few variables and visualize the outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958ecd2b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "958ecd2b",
    "outputId": "50a09a5f-9fa9-41a5-dee1-877971c36409"
   },
   "outputs": [],
   "source": [
    "n_cont = len(cont_attr)\n",
    "cat_list = [np.array(list(dropdown_encoders[name].values())) for name in cat_attr]\n",
    "\n",
    "n_cont, cat_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929a9286",
   "metadata": {},
   "source": [
    "The `n_cont` variable contains the number of continuous attributes you're using. The `cat_list` variable contains a list of lists, each inner list containing the unique values corresponding to one of the categorical attributes (\"dropdowns\").\n",
    "\n",
    "Both variables, together with the number of embedding dimensions you chose (`emb_dim`), should be used as arguments to create an instance of your custom model class (`FFN`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cefb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# write your code here\n",
    "emb_dim = 5\n",
    "model = FFN(n_cont, cat_list, emb_dim=emb_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c270c53f",
   "metadata": {},
   "source": [
    "Now, create the appropriate loss function for the task:\n",
    "\n",
    "![](https://raw.githubusercontent.com/dvgodoy/assets/main/PyTorchInPractice/images/ch0/model_step2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32c86aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a13a0a1",
   "metadata": {},
   "source": [
    "Then, create an optimizer that will update your model's parameters:\n",
    "\n",
    "![](https://raw.githubusercontent.com/dvgodoy/assets/main/PyTorchInPractice/images/ch0/model_step3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf85efc7",
   "metadata": {
    "id": "bf85efc7"
   },
   "outputs": [],
   "source": [
    "# Suggested learning rate\n",
    "lr = 3e-3\n",
    "\n",
    "# write your code here\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290c12c2",
   "metadata": {
    "id": "290c12c2"
   },
   "source": [
    "Next, you will write the training loop using the data loaders to iterate through your training and validation data (these loops are written for you already).\n",
    "\n",
    "![](https://raw.githubusercontent.com/dvgodoy/assets/main/PyTorchInPractice/images/ch0/model_step4.png)\n",
    "\n",
    "The training loop itself is pretty much the same as in the previous lab, but don't forget your data loaders return dictionaries now, so you'll need to adjust they way your data is being sent to the appropriate device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e465e31",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9e465e31",
    "outputId": "a8291fa7-4e7f-4cce-b605-95015fab7813"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "n_epochs = 20\n",
    "\n",
    "losses = torch.empty(n_epochs)\n",
    "val_losses = torch.empty(n_epochs)\n",
    "\n",
    "best_loss = torch.inf\n",
    "best_epoch = -1\n",
    "patience = 3\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "progress_bar = tqdm(range(n_epochs))\n",
    "\n",
    "for epoch in progress_bar:\n",
    "    batch_losses = []\n",
    "    \n",
    "    ## Training\n",
    "    for i, batch in enumerate(dataloaders['train']):\n",
    "        # Set the model to training mode\n",
    "        # write your code here\n",
    "        model.train()\n",
    "                \n",
    "        # Send batch features and targets to the device\n",
    "        # write your code here\n",
    "        batch['cont_X'] = batch['cont_X'].to(device)\n",
    "        batch['cat_X'] = batch['cat_X'].to(device)\n",
    "        batch['label'] = batch['label'].to(device)\n",
    "        \n",
    "        # Step 1 - forward pass\n",
    "        # write your code here\n",
    "        predictions = model(batch)\n",
    "\n",
    "        # Step 2 - computing the loss\n",
    "        # write your code here\n",
    "        loss = loss_fn(predictions, batch['label'])\n",
    "\n",
    "        # Step 3 - computing the gradients\n",
    "        # Tip: it requires a single method call to backpropagate gradients\n",
    "        # write your code here\n",
    "        loss.backward()\n",
    "\n",
    "        batch_losses.append(loss.item())\n",
    "\n",
    "        # Step 4 - updating parameters and zeroing gradients\n",
    "        # Tip: it takes two calls to optimizer's methods\n",
    "        # write your code here\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "    losses[epoch] = torch.tensor(batch_losses).mean()\n",
    "\n",
    "    ## Validation   \n",
    "    with torch.inference_mode():\n",
    "        batch_losses = []\n",
    "\n",
    "        for i, val_batch in enumerate(dataloaders['val']):\n",
    "            # Set the model to evaluation mode\n",
    "            # write your code here\n",
    "            model.eval()\n",
    "\n",
    "            # Send batch features and targets to the device\n",
    "            # write your code here\n",
    "            val_batch['cont_X'] = val_batch['cont_X'].to(device)\n",
    "            val_batch['cat_X'] = val_batch['cat_X'].to(device)\n",
    "            val_batch['label'] = val_batch['label'].to(device)\n",
    "\n",
    "            # Step 1 - forward pass\n",
    "            # write your code here\n",
    "            predictions = model(val_batch)\n",
    "\n",
    "            # Step 2 - computing the loss\n",
    "            # write your code here\n",
    "            loss = loss_fn(predictions, val_batch['label'])\n",
    "\n",
    "            batch_losses.append(loss.item())\n",
    "\n",
    "        val_losses[epoch] = torch.tensor(batch_losses).mean()\n",
    "        \n",
    "        if val_losses[epoch] < best_loss:\n",
    "            best_loss = val_losses[epoch]\n",
    "            best_epoch = epoch\n",
    "            torch.save({'model': model.state_dict(),\n",
    "                        'optimizer': optimizer.state_dict()},\n",
    "                       'best_model.pth')\n",
    "        elif (epoch - best_epoch) > patience:\n",
    "            print(f\"Early stopping at epoch #{epoch}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0f2bcb",
   "metadata": {
    "id": "6a0f2bcb"
   },
   "source": [
    "Let's check the evolution of the losses. Run the cell below as is to plot your losses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a0b5b1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "48a0b5b1",
    "outputId": "01751658-c39f-4fc8-f828-18eca51c0e2e"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(losses[:epoch], label='Training')\n",
    "plt.plot(val_losses[:epoch], label='Validation')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.yscale('log')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f78468",
   "metadata": {
    "id": "62f78468"
   },
   "source": [
    "Then, let's compare predicted and actual values in the validation set.\n",
    "\n",
    "![](https://raw.githubusercontent.com/dvgodoy/assets/main/PyTorchInPractice/images/ch0/model_step5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1f7f48",
   "metadata": {},
   "source": [
    "Run the cell below as is to visualize a scatterplot comparing predicted and actual values of fuel consumption. A perfect prediction corresponds to the dashed diagonal line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e556b858",
   "metadata": {
    "id": "e556b858"
   },
   "outputs": [],
   "source": [
    "split = 'val'\n",
    "y_hat = []\n",
    "y_true = []\n",
    "for batch in dataloaders[split]:\n",
    "    model.eval()\n",
    "    batch['cont_X'] = batch['cont_X'].to(device)\n",
    "    batch['cat_X'] = batch['cat_X'].to(device)\n",
    "    batch['label'] = batch['label'].to(device)\n",
    "    y_hat.extend(model(batch).tolist())\n",
    "    y_true.extend(batch['label'].tolist())\n",
    "    \n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "ax.scatter(y_true, y_hat, alpha=0.25)\n",
    "ax.plot([0, 80000], [0, 80000], linestyle='--', c='k', linewidth=1)\n",
    "ax.set_xlabel('Actual')\n",
    "ax.set_xlim([0, 80000])\n",
    "ax.set_ylabel('Predicted')\n",
    "ax.set_ylim([0, 80000])\n",
    "ax.set_title('Price')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c95fa2",
   "metadata": {
    "id": "58c95fa2"
   },
   "source": [
    "Ideally, you'll see a cloud of points around the diagonal line. What about the R2 score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3383bd06",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3383bd06",
    "outputId": "63795bfb-9ef0-4bb5-e4ee-d4e19cee4e35"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_true, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e67afc7",
   "metadata": {
    "id": "8e67afc7"
   },
   "source": [
    "If your cloud of points were indeed around the diagonal line, you're probably expecting a high R2 score (>0.8). If you got a surprisingly low value for it, can you guess why?\n",
    "\n",
    "TIP: Try removing the `set_ylim()` range and look for extreme or negative values. If, for some reason, your model is producing extreme predictions (even if there's only a few of them), it may impact negatively the R2 score."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
